{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final-Meenakshi_Sambamurthy_DeformableC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meenasambamurthy/mlblr/blob/master/Final_DeformableC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OIYCP4dIMm2A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Limitations of ConvNets wrt modeling of geometric transformations**\n",
        "\n",
        "Current models of ConvNets are limited when it comes to handling large complex geometric transformations (such as object scale, pose, viewpoint, part deformation) in image/video datasets. \n",
        "\n",
        "This is because they inherently assume such transformations are \"fixed\", \"small\" and \"known\", and with this  so called \"prior knowledge\" is able to model with poor workarounds such as \n",
        "1)  handcrafted \"invariant\" features and algorithms that are  difficult or infeasible for complex transformations\n",
        "2)use of large model capacity, complex and large no of parameters, expensive training and/or\n",
        "3) extensive data augmentation, though introducing  sufficient desired variations, also uses fixed and pre-determined transformations.\n",
        "\n",
        "Such ConvNets are ultimately unable to generalize to new task processing unknown transformations. \n",
        "\n",
        "What is needed in them is a way to encode semantics that can be distinguished over spatial locations. For example, different locations can correspond to different scales or deformation of objects.\n",
        "\n",
        "**Deformable Convolution**\n",
        "\n",
        "Deformable Convolution introduces \"adaptively learnt\" offsets to  convolution layer and ROI pooling layer. The offsets are adaptively learned from the preceding feature maps and ROIs , which adds a small amount of parameters and computation and easily trained with back propagation.\n",
        "\n",
        "1. By introducing 2D offsets to the fixed sampling locations of convolution layer, the receptive field and the sampling locations are adaptively adjusted to the objects' scale and shape. The fixed or same Receptive Field size of all activations in one layer no longer holds. Such adaptive determination of scale(different locations correspond to different scale or deformation of object) is needed for visual recognition with fine localization (\"semantic segmentation\")\n",
        "\n",
        "2. ROI pooling technique converts input rectangular region of arbitrary size in to fixed size features, eg the bounding box YOLO model. However this is still a primitive way of modeling non-rigid objects. With  deformable convolution, in the RoI pooling layer, the offset is introduced to each bin position of the previous ROI layer, thus making the parts deviate from the RoI bins and move on to the nearby foreground region, enhancing localization capability for modeling non-rigid objects. \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "NBM-7BqE6pD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2045
        },
        "outputId": "b2c518b7-9833-40d5-ef0c-5a475ffaa4d0"
      },
      "cell_type": "code",
      "source": [
        "#Deformable Convolution Project\n",
        "#The idea of the project is to first run the code as is, in one place and comment for further elucidation\n",
        "\n",
        "from __future__ import division\n",
        "# %env CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam, SGD\n",
        "from __future__ import absolute_import, division\n",
        "from scipy.ndimage.interpolation import map_coordinates as sp_map_coordinates\n",
        "from keras.layers import Conv2D\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python import debug as tf_debug\n",
        "import keras.utils\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.Session(config=config)\n",
        "K.set_session(sess)\n",
        "\n",
        "from keras.layers import Input, Conv2D, Activation, GlobalAvgPool2D, Dense, BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "def keras_set_tf_debug():\n",
        "    sess = K.get_session()\n",
        "    sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
        "    sess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\n",
        "    K.set_session(sess)\n",
        "\n",
        "\n",
        "\n",
        "def get_mnist_dataset():\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    X_train = X_train.astype('float32') / 255\n",
        "    X_test = X_test.astype('float32') / 255\n",
        "    X_train = X_train[..., None]\n",
        "    X_test = X_test[..., None]\n",
        "    Y_train = keras.utils.to_categorical(y_train, 10)\n",
        "    Y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "    return (X_train, Y_train), (X_test, Y_test)\n",
        "\n",
        "\n",
        "def get_gen(set_name, batch_size, translate, scale,\n",
        "            shuffle=True):\n",
        "    if set_name == 'train':\n",
        "        (X, Y), _ = get_mnist_dataset()\n",
        "    elif set_name == 'test':\n",
        "        _, (X, Y) = get_mnist_dataset()\n",
        "\n",
        "    image_gen = ImageDataGenerator(\n",
        "        zoom_range=scale,\n",
        "        width_shift_range=translate,\n",
        "        height_shift_range=translate\n",
        "    )\n",
        "    gen = image_gen.flow(X, Y, batch_size=batch_size, shuffle=shuffle)\n",
        "    return gen\n",
        "\n",
        "def tf_flatten(a):\n",
        "    \"\"\"Flatten tensor\"\"\"\n",
        "    return tf.reshape(a, [-1])\n",
        "\n",
        "\n",
        "def tf_repeat(a, repeats, axis=0):\n",
        "    \"\"\"TensorFlow version of np.repeat for 1D\"\"\"\n",
        "    # https://github.com/tensorflow/tensorflow/issues/8521\n",
        "    assert len(a.get_shape()) == 1\n",
        "\n",
        "    a = tf.expand_dims(a, -1)\n",
        "    a = tf.tile(a, [1, repeats])\n",
        "    a = tf_flatten(a)\n",
        "    return a\n",
        "\n",
        "\n",
        "def tf_repeat_2d(a, repeats):\n",
        "    \"\"\"Tensorflow version of np.repeat for 2D\"\"\"\n",
        "\n",
        "    assert len(a.get_shape()) == 2\n",
        "    a = tf.expand_dims(a, 0)\n",
        "    a = tf.tile(a, [repeats, 1, 1])\n",
        "    return a\n",
        "\n",
        "\n",
        "def tf_map_coordinates(input, coords, order=1):\n",
        "    \"\"\"Tensorflow verion of scipy.ndimage.map_coordinates\n",
        "    Note that coords is transposed and only 2D is supported\n",
        "    Parameters\n",
        "    ----------\n",
        "    input : tf.Tensor. shape = (s, s)\n",
        "    coords : tf.Tensor. shape = (n_points, 2)\n",
        "    \"\"\"\n",
        "\n",
        "    assert order == 1\n",
        "\n",
        "    coords_lt = tf.cast(tf.floor(coords), 'int32')\n",
        "    coords_rb = tf.cast(tf.ceil(coords), 'int32')\n",
        "    coords_lb = tf.stack([coords_lt[:, 0], coords_rb[:, 1]], axis=1)\n",
        "    coords_rt = tf.stack([coords_rb[:, 0], coords_lt[:, 1]], axis=1)\n",
        "\n",
        "    vals_lt = tf.gather_nd(input, coords_lt)\n",
        "    vals_rb = tf.gather_nd(input, coords_rb)\n",
        "    vals_lb = tf.gather_nd(input, coords_lb)\n",
        "    vals_rt = tf.gather_nd(input, coords_rt)\n",
        "\n",
        "    coords_offset_lt = coords - tf.cast(coords_lt, 'float32')\n",
        "    vals_t = vals_lt + (vals_rt - vals_lt) * coords_offset_lt[:, 0]\n",
        "    vals_b = vals_lb + (vals_rb - vals_lb) * coords_offset_lt[:, 0]\n",
        "    mapped_vals = vals_t + (vals_b - vals_t) * coords_offset_lt[:, 1]\n",
        "\n",
        "    return mapped_vals\n",
        "\n",
        "\n",
        "def sp_batch_map_coordinates(inputs, coords):\n",
        "    \"\"\"Reference implementation for batch_map_coordinates\"\"\"\n",
        "    coords = coords.clip(0, inputs.shape[1] - 1)\n",
        "    mapped_vals = np.array([\n",
        "        sp_map_coordinates(input, coord.T, mode='nearest', order=1)\n",
        "        for input, coord in zip(inputs, coords)\n",
        "    ])\n",
        "    return mapped_vals\n",
        "\n",
        "\n",
        "def tf_batch_map_coordinates(input, coords, order=1):\n",
        "    \"\"\"Batch version of tf_map_coordinates\n",
        "    Only supports 2D feature maps\n",
        "    Parameters\n",
        "    ----------\n",
        "    input : tf.Tensor. shape = (b, s, s)\n",
        "    coords : tf.Tensor. shape = (b, n_points, 2)\n",
        "    Returns\n",
        "    -------\n",
        "    tf.Tensor. shape = (b, s, s)\n",
        "    \"\"\"\n",
        "\n",
        "    input_shape = tf.shape(input)\n",
        "    batch_size = input_shape[0]\n",
        "    input_size = input_shape[1]\n",
        "    n_coords = tf.shape(coords)[1]\n",
        "\n",
        "    coords = tf.clip_by_value(coords, 0, tf.cast(input_size, 'float32') - 1)\n",
        "    coords_lt = tf.cast(tf.floor(coords), 'int32')\n",
        "    coords_rb = tf.cast(tf.ceil(coords), 'int32')\n",
        "    coords_lb = tf.stack([coords_lt[..., 0], coords_rb[..., 1]], axis=-1)\n",
        "    coords_rt = tf.stack([coords_rb[..., 0], coords_lt[..., 1]], axis=-1)\n",
        "\n",
        "    idx = tf_repeat(tf.range(batch_size), n_coords)\n",
        "\n",
        "    def _get_vals_by_coords(input, coords):\n",
        "        indices = tf.stack([\n",
        "            idx, tf_flatten(coords[..., 0]), tf_flatten(coords[..., 1])\n",
        "        ], axis=-1)\n",
        "        vals = tf.gather_nd(input, indices)\n",
        "        vals = tf.reshape(vals, (batch_size, n_coords))\n",
        "        return vals\n",
        "\n",
        "    vals_lt = _get_vals_by_coords(input, coords_lt)\n",
        "    vals_rb = _get_vals_by_coords(input, coords_rb)\n",
        "    vals_lb = _get_vals_by_coords(input, coords_lb)\n",
        "    vals_rt = _get_vals_by_coords(input, coords_rt)\n",
        "\n",
        "    coords_offset_lt = coords - tf.cast(coords_lt, 'float32')\n",
        "    vals_t = vals_lt + (vals_rt - vals_lt) * coords_offset_lt[..., 0]\n",
        "    vals_b = vals_lb + (vals_rb - vals_lb) * coords_offset_lt[..., 0]\n",
        "    mapped_vals = vals_t + (vals_b - vals_t) * coords_offset_lt[..., 1]\n",
        "\n",
        "    return mapped_vals\n",
        "\n",
        "\n",
        "def sp_batch_map_offsets(input, offsets):\n",
        "    \"\"\"Reference implementation for tf_batch_map_offsets\"\"\"\n",
        "\n",
        "    batch_size = input.shape[0]\n",
        "    input_size = input.shape[1]\n",
        "\n",
        "    offsets = offsets.reshape(batch_size, -1, 2)\n",
        "    grid = np.stack(np.mgrid[:input_size, :input_size], -1).reshape(-1, 2)\n",
        "    grid = np.repeat([grid], batch_size, axis=0)\n",
        "    coords = offsets + grid\n",
        "    coords = coords.clip(0, input_size - 1)\n",
        "\n",
        "    mapped_vals = sp_batch_map_coordinates(input, coords)\n",
        "    return mapped_vals\n",
        "\n",
        "\n",
        "def tf_batch_map_offsets(input, offsets, order=1):\n",
        "    \"\"\"Batch map offsets into input\n",
        "    Parameters\n",
        "    ---------\n",
        "    input : tf.Tensor. shape = (b, s, s)\n",
        "    offsets: tf.Tensor. shape = (b, s, s, 2)\n",
        "    Returns\n",
        "    -------\n",
        "    tf.Tensor. shape = (b, s, s)\n",
        "    \"\"\"\n",
        "\n",
        "    input_shape = tf.shape(input)\n",
        "    batch_size = input_shape[0]\n",
        "    input_size = input_shape[1]\n",
        "\n",
        "    offsets = tf.reshape(offsets, (batch_size, -1, 2))\n",
        "    grid = tf.meshgrid(\n",
        "        tf.range(input_size), tf.range(input_size), indexing='ij'\n",
        "    )\n",
        "    grid = tf.stack(grid, axis=-1)\n",
        "    grid = tf.cast(grid, 'float32')\n",
        "    grid = tf.reshape(grid, (-1, 2))\n",
        "    grid = tf_repeat_2d(grid, batch_size)\n",
        "    coords = offsets + grid\n",
        "\n",
        "    mapped_vals = tf_batch_map_coordinates(input, coords)\n",
        "    return mapped_vals\n",
        "\n",
        "def get_cnn():\n",
        "    inputs = l = Input((28, 28, 1), name='input')\n",
        "\n",
        "    # conv11\n",
        "    l = Conv2D(32, (3, 3), padding='same', name='conv11')(l)\n",
        "    l = Activation('relu', name='conv11_relu')(l)\n",
        "    l = BatchNormalization(name='conv11_bn')(l)\n",
        "\n",
        "    # conv12\n",
        "    l = Conv2D(64, (3, 3), padding='same', strides=(2, 2), name='conv12')(l)\n",
        "    l = Activation('relu', name='conv12_relu')(l)\n",
        "    l = BatchNormalization(name='conv12_bn')(l)\n",
        "\n",
        "    # conv21\n",
        "    l = Conv2D(128, (3, 3), padding='same', name='conv21')(l)\n",
        "    l = Activation('relu', name='conv21_relu')(l)\n",
        "    l = BatchNormalization(name='conv21_bn')(l)\n",
        "\n",
        "    # conv22\n",
        "    l = Conv2D(128, (3, 3), padding='same', strides=(2, 2), name='conv22')(l)\n",
        "    l = Activation('relu', name='conv22_relu')(l)\n",
        "    l = BatchNormalization(name='conv22_bn')(l)\n",
        "\n",
        "    # out\n",
        "    l = GlobalAvgPool2D(name='avg_pool')(l)\n",
        "    l = Dense(10, name='fc1')(l)\n",
        "    outputs = l = Activation('softmax', name='out')(l)\n",
        "\n",
        "    return inputs, outputs\n",
        "  \n",
        "from keras.callbacks import Callback\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "class TensorBoard(Callback):\n",
        "    \"\"\"Tensorboard basic visualizations\"\"\"\n",
        "\n",
        "    def __init__(self, log_dir='./logs',\n",
        "                 histogram_freq=0,\n",
        "                 write_graph=True,\n",
        "                 write_images=False):\n",
        "        super(TensorBoard, self).__init__()\n",
        "        if K.backend() != 'tensorflow':\n",
        "            raise RuntimeError('TensorBoard callback only works '\n",
        "                               'with the TensorFlow backend.')\n",
        "        self.log_dir = log_dir\n",
        "        self.histogram_freq = histogram_freq\n",
        "        self.merged = None\n",
        "        self.write_graph = write_graph\n",
        "        self.write_images = write_images\n",
        "\n",
        "    def set_model(self, model):\n",
        "        self.model = model\n",
        "        self.sess = K.get_session()\n",
        "        total_loss = self.model.total_loss\n",
        "        if self.histogram_freq and self.merged is None:\n",
        "            for layer in self.model.layers:\n",
        "                for weight in layer.weights:\n",
        "                    # dense_1/bias:0 > dense_1/bias_0\n",
        "                    name = weight.name.replace(':', '_')\n",
        "                    tf.summary.histogram(name, weight)\n",
        "                    tf.summary.histogram(\n",
        "                        '{}_gradients'.format(name),\n",
        "                        K.gradients(total_loss, [weight])[0]\n",
        "                    )\n",
        "                    if self.write_images:\n",
        "                        w_img = tf.squeeze(weight)\n",
        "                        shape = w_img.get_shape()\n",
        "                        if len(shape) > 1 and shape[0] > shape[1]:\n",
        "                            w_img = tf.transpose(w_img)\n",
        "                        if len(shape) == 1:\n",
        "                            w_img = tf.expand_dims(w_img, 0)\n",
        "                        w_img = tf.expand_dims(tf.expand_dims(w_img, 0), -1)\n",
        "                        tf.summary.image(name, w_img)\n",
        "\n",
        "                if hasattr(layer, 'output'):\n",
        "                    tf.summary.histogram('{}_out'.format(layer.name),\n",
        "                                         layer.output)\n",
        "        self.merged = tf.summary.merge_all()\n",
        "\n",
        "        if self.write_graph:\n",
        "            self.writer = tf.summary.FileWriter(self.log_dir,\n",
        "                                                self.sess.graph)\n",
        "        else:\n",
        "            self.writer = tf.summary.FileWriter(self.log_dir)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.validation_data and self.histogram_freq:\n",
        "            if epoch % self.histogram_freq == 0:\n",
        "                # TODO: implement batched calls to sess.run\n",
        "                # (current call will likely go OOM on GPU)\n",
        "                if self.model.uses_learning_phase:\n",
        "                    cut_v_data = len(self.model.inputs)\n",
        "                    val_data = self.validation_data[:cut_v_data][:32] + [0]\n",
        "                    tensors = self.model.inputs + self.model.targets + [K.learning_phase()]\n",
        "                else:\n",
        "                    val_data = self.validation_data\n",
        "                    tensors = self.model.inputs + self.model.targets\n",
        "\n",
        "                feed_dict = dict(zip(tensors, val_data))\n",
        "                sample_weights = self.model.sample_weights\n",
        "                for w in sample_weights:\n",
        "                    w_val = np.ones(len(val_data[0]), dtype=np.float32)\n",
        "                    feed_dict.update({w.name: w_val})\n",
        "                result = self.sess.run([self.merged], feed_dict=feed_dict)\n",
        "                summary_str = result[0]\n",
        "                self.writer.add_summary(summary_str, epoch)\n",
        "\n",
        "        for name, value in logs.items():\n",
        "            if name in ['batch', 'size']:\n",
        "                continue\n",
        "\n",
        "            if name[:3] != 'val':\n",
        "                name = 'train_' + name\n",
        "\n",
        "            summary = tf.Summary()\n",
        "            summary_value = summary.value.add()\n",
        "            summary_value.simple_value = value.item()\n",
        "            summary_value.tag = name\n",
        "            self.writer.add_summary(summary, epoch)\n",
        "        self.writer.flush()\n",
        "\n",
        "    def on_train_end(self, _):\n",
        "        self.writer.close()\n",
        "\n",
        "  \n",
        "def get_deform_cnn(trainable):\n",
        "    inputs = l = Input((28, 28, 1), name='input')\n",
        "\n",
        "    # conv11\n",
        "    l = Conv2D(32, (3, 3), padding='same', name='conv11', trainable=trainable)(l)\n",
        "    l = Activation('relu', name='conv11_relu')(l)\n",
        "    l = BatchNormalization(name='conv11_bn')(l)\n",
        "\n",
        "    # conv12\n",
        "    l_offset = ConvOffset2D(32, name='conv12_offset')(l)\n",
        "    l = Conv2D(64, (3, 3), padding='same', strides=(2, 2), name='conv12', trainable=trainable)(l_offset)\n",
        "    l = Activation('relu', name='conv12_relu')(l)\n",
        "    l = BatchNormalization(name='conv12_bn')(l)\n",
        "\n",
        "    # conv21\n",
        "    l_offset = ConvOffset2D(64, name='conv21_offset')(l)\n",
        "    l = Conv2D(128, (3, 3), padding='same', name='conv21', trainable=trainable)(l_offset)\n",
        "    l = Activation('relu', name='conv21_relu')(l)\n",
        "    l = BatchNormalization(name='conv21_bn')(l)\n",
        "\n",
        "    # conv22\n",
        "    l_offset = ConvOffset2D(128, name='conv22_offset')(l)\n",
        "    l = Conv2D(128, (3, 3), padding='same', strides=(2, 2), name='conv22', trainable=trainable)(l_offset)\n",
        "    l = Activation('relu', name='conv22_relu')(l)\n",
        "    l = BatchNormalization(name='conv22_bn')(l)\n",
        "\n",
        "    # out\n",
        "    l = GlobalAvgPool2D(name='avg_pool')(l)\n",
        "    l = Dense(10, name='fc1', trainable=trainable)(l)\n",
        "    outputs = l = Activation('softmax', name='out')(l)\n",
        "\n",
        "    return inputs, outputs\n",
        "\n",
        "class ConvOffset2D(Conv2D):\n",
        "    \"\"\"ConvOffset2D\n",
        "    Convolutional layer responsible for learning the 2D offsets and output the\n",
        "    deformed feature map using bilinear interpolation\n",
        "    Note that this layer does not perform convolution on the deformed feature\n",
        "    map. See get_deform_cnn for usage\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, filters, init_normal_stddev=0.01, **kwargs):\n",
        "        \"\"\"Init\n",
        "        Parameters\n",
        "        ----------\n",
        "        filters : int\n",
        "            Number of channel of the input feature map\n",
        "        init_normal_stddev : float\n",
        "            Normal kernel initialization\n",
        "        **kwargs:\n",
        "            Pass to superclass. See Con2D layer in Keras\n",
        "        \"\"\"\n",
        "\n",
        "        self.filters = filters\n",
        "        super(ConvOffset2D, self).__init__(\n",
        "            self.filters * 2, (3, 3), padding='same', use_bias=False,\n",
        "            kernel_initializer=RandomNormal(0, init_normal_stddev),\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"Return the deformed featured map\"\"\"\n",
        "        x_shape = x.get_shape()\n",
        "        offsets = super(ConvOffset2D, self).call(x)\n",
        "\n",
        "        # offsets: (b*c, h, w, 2)\n",
        "        offsets = self._to_bc_h_w_2(offsets, x_shape)\n",
        "\n",
        "        # x: (b*c, h, w)\n",
        "        x = self._to_bc_h_w(x, x_shape)\n",
        "\n",
        "        # X_offset: (b*c, h, w)\n",
        "        x_offset = tf_batch_map_offsets(x, offsets)\n",
        "\n",
        "        # x_offset: (b, h, w, c)\n",
        "        x_offset = self._to_b_h_w_c(x_offset, x_shape)\n",
        "\n",
        "        return x_offset\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"Output shape is the same as input shape\n",
        "        Because this layer does only the deformation part\n",
        "        \"\"\"\n",
        "        return input_shape\n",
        "\n",
        "    @staticmethod\n",
        "    def _to_bc_h_w_2(x, x_shape):\n",
        "        \"\"\"(b, h, w, 2c) -> (b*c, h, w, 2)\"\"\"\n",
        "        x = tf.transpose(x, [0, 3, 1, 2])\n",
        "        x = tf.reshape(x, (-1, int(x_shape[1]), int(x_shape[2]), 2))\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def _to_bc_h_w(x, x_shape):\n",
        "        \"\"\"(b, h, w, c) -> (b*c, h, w)\"\"\"\n",
        "        x = tf.transpose(x, [0, 3, 1, 2])\n",
        "        x = tf.reshape(x, (-1, int(x_shape[1]), int(x_shape[2])))\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def _to_b_h_w_c(x, x_shape):\n",
        "        \"\"\"(b*c, h, w) -> (b, h, w, c)\"\"\"\n",
        "        x = tf.reshape(\n",
        "            x, (-1, int(x_shape[3]), int(x_shape[1]), int(x_shape[2]))\n",
        "        )\n",
        "        x = tf.transpose(x, [0, 2, 3, 1])\n",
        "        return x\n",
        "\n",
        "# ---\n",
        "# Config\n",
        "\n",
        "batch_size = 32\n",
        "n_train = 60000\n",
        "n_test = 10000\n",
        "steps_per_epoch = int(np.ceil(n_train / batch_size))\n",
        "validation_steps = int(np.ceil(n_test / batch_size))\n",
        "\n",
        "train_gen = get_gen(\n",
        "    'train', batch_size=batch_size,\n",
        "    scale=(1.0, 1.0), translate=0.0,\n",
        "    shuffle=True\n",
        ")\n",
        "test_gen = get_gen(\n",
        "    'test', batch_size=batch_size,\n",
        "    scale=(1.0, 1.0), translate=0.0,\n",
        "    shuffle=False\n",
        ")\n",
        "train_scaled_gen = get_gen(\n",
        "    'train', batch_size=batch_size,\n",
        "    scale=(1.0, 2.5), translate=0.2,\n",
        "    shuffle=True\n",
        ")\n",
        "test_scaled_gen = get_gen(\n",
        "    'test', batch_size=batch_size,\n",
        "    scale=(1.0, 2.5), translate=0.2,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "# ---\n",
        "# Normal CNN\n",
        "\n",
        "inputs, outputs = get_cnn()\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "optim = Adam(1e-3)\n",
        "# optim = SGD(1e-3, momentum=0.99, nesterov=True)\n",
        "loss = categorical_crossentropy\n",
        "model.compile(optim, loss, metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_gen, steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10, verbose=1,\n",
        "    validation_data=test_gen, validation_steps=validation_steps\n",
        ")\n",
        "model.save_weights('cnn.h5')\n",
        "# 1875/1875 [==============================] - 24s - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0528 - val_acc: 0.9858\n",
        "\n",
        "# ---\n",
        "# Evaluate normal CNN\n",
        "\n",
        "model.load_weights('cnn.h5', by_name=True)\n",
        "\n",
        "val_loss, val_acc = model.evaluate_generator(\n",
        "    test_gen, steps=validation_steps\n",
        ")\n",
        "print('Test accuracy', val_acc)\n",
        "# 0.9874\n",
        "\n",
        "val_loss, val_acc = model.evaluate_generator(\n",
        "    test_scaled_gen, steps=validation_steps\n",
        ")\n",
        "print('Test accuracy with scaled images', val_acc)\n",
        "# 0.5701\n",
        "\n",
        "# ---\n",
        "# Deformable CNN\n",
        "\n",
        "inputs, outputs = get_deform_cnn(trainable=False)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.load_weights('cnn.h5', by_name=True)\n",
        "model.summary()\n",
        "optim = Adam(5e-4)\n",
        "# optim = SGD(1e-4, momentum=0.99, nesterov=True)\n",
        "loss = categorical_crossentropy\n",
        "model.compile(optim, loss, metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_scaled_gen, steps_per_epoch=steps_per_epoch,\n",
        "    epochs=20, verbose=1,\n",
        "    validation_data=test_scaled_gen, validation_steps=validation_steps\n",
        ")\n",
        "# Epoch 20/20\n",
        "# 1875/1875 [==============================] - 504s - loss: 0.2838 - acc: 0.9122 - val_loss: 0.2359 - val_acc: 0.9231\n",
        "model.save_weights('deform_cnn.h5')\n",
        "\n",
        "# --\n",
        "# Evaluate deformable CNN\n",
        "\n",
        "model.load_weights('deform_cnn.h5')\n",
        "\n",
        "val_loss, val_acc = model.evaluate_generator(\n",
        "    test_scaled_gen, steps=validation_steps\n",
        ")\n",
        "print('Test accuracy of deformable convolution with scaled images', val_acc)\n",
        "# 0.9255\n",
        "\n",
        "val_loss, val_acc = model.evaluate_generator(\n",
        "    test_gen, steps=validation_steps\n",
        ")\n",
        "print('Test accuracy of deformable convolution with regular images', val_acc)\n",
        "# 0.9727\n",
        "\n",
        "deform_conv_layers = [l for l in model.layers if isinstance(l, ConvOffset2D)]\n",
        "\n",
        "Xb, Yb = next(test_gen)\n",
        "for l in deform_conv_layers:\n",
        "    print(l)\n",
        "    _model = Model(inputs=inputs, outputs=l.output)\n",
        "    offsets = _model.predict(Xb)\n",
        "    offsets = offsets.reshape(offsets.shape[0], offsets.shape[1], offsets.shape[2], -1, 2)\n",
        "    print(offsets.min())\n",
        "    print(offsets.mean())\n",
        "    print(offsets.max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv11 (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv11_relu (Activation)     (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv11_bn (BatchNormalizatio (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv12 (Conv2D)              (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv12_relu (Activation)     (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv12_bn (BatchNormalizatio (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv21 (Conv2D)              (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv21_relu (Activation)     (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv21_bn (BatchNormalizatio (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv22 (Conv2D)              (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv22_relu (Activation)     (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv22_bn (BatchNormalizatio (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "avg_pool (GlobalAveragePooli (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "out (Activation)             (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 242,954\n",
            "Trainable params: 242,250\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "  83/1875 [>.............................] - ETA: 1:15 - loss: 1.0286 - acc: 0.7285"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 50s 27ms/step - loss: 0.1573 - acc: 0.9590 - val_loss: 0.0901 - val_acc: 0.9729\n",
            "Epoch 2/10\n",
            " 494/1875 [======>.......................] - ETA: 33s - loss: 0.0511 - acc: 0.9856"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0485 - acc: 0.9857 - val_loss: 0.0592 - val_acc: 0.9814\n",
            "Epoch 3/10\n",
            " 680/1875 [=========>....................] - ETA: 28s - loss: 0.0342 - acc: 0.9902"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 48s 25ms/step - loss: 0.0344 - acc: 0.9895 - val_loss: 0.0344 - val_acc: 0.9884\n",
            "Epoch 4/10\n",
            " 739/1875 [==========>...................] - ETA: 27s - loss: 0.0272 - acc: 0.9915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0266 - acc: 0.9914 - val_loss: 0.0403 - val_acc: 0.9854\n",
            "Epoch 5/10\n",
            " 734/1875 [==========>...................] - ETA: 27s - loss: 0.0207 - acc: 0.9936"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0308 - val_acc: 0.9898\n",
            "Epoch 6/10\n",
            " 730/1875 [==========>...................] - ETA: 28s - loss: 0.0153 - acc: 0.9951"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0301 - val_acc: 0.9899\n",
            "Epoch 7/10\n",
            " 795/1875 [===========>..................] - ETA: 25s - loss: 0.0098 - acc: 0.9972"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0261 - val_acc: 0.9910\n",
            "Epoch 8/10\n",
            " 756/1875 [===========>..................] - ETA: 27s - loss: 0.0103 - acc: 0.9971"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.0271 - val_acc: 0.9922\n",
            "Epoch 9/10\n",
            " 782/1875 [===========>..................] - ETA: 26s - loss: 0.0083 - acc: 0.9975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.0425 - val_acc: 0.9871\n",
            "Epoch 10/10\n",
            " 812/1875 [===========>..................] - ETA: 25s - loss: 0.0073 - acc: 0.9977"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0568 - val_acc: 0.9831\n",
            "Test accuracy 0.9831\n",
            "Test accuracy with scaled images 0.6779\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv11 (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv11_relu (Activation)     (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv11_bn (BatchNormalizatio (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv12_offset (ConvOffset2D) (None, 28, 28, 32)        18432     \n",
            "_________________________________________________________________\n",
            "conv12 (Conv2D)              (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv12_relu (Activation)     (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv12_bn (BatchNormalizatio (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv21_offset (ConvOffset2D) (None, 14, 14, 64)        73728     \n",
            "_________________________________________________________________\n",
            "conv21 (Conv2D)              (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv21_relu (Activation)     (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv21_bn (BatchNormalizatio (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv22_offset (ConvOffset2D) (None, 14, 14, 128)       294912    \n",
            "_________________________________________________________________\n",
            "conv22 (Conv2D)              (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv22_relu (Activation)     (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv22_bn (BatchNormalizatio (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "avg_pool (GlobalAveragePooli (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "out (Activation)             (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 630,026\n",
            "Trainable params: 387,776\n",
            "Non-trainable params: 242,250\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "  19/1875 [..............................] - ETA: 13:32 - loss: 0.9056 - acc: 0.7500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.2917 - acc: 0.9135"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1875/1875 [==============================] - 789s 421ms/step - loss: 0.2919 - acc: 0.9135 - val_loss: 0.2090 - val_acc: 0.9349\n",
            "Epoch 2/20\n",
            " 327/1875 [====>.........................] - ETA: 9:25 - loss: 0.2656 - acc: 0.9186"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1029/1875 [===============>..............] - ETA: 5:08 - loss: 0.2615 - acc: 0.9211"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}